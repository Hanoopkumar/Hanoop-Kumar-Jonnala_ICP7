{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81f40a-f557-465e-903a-61eb36a39025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 18:11:27.484372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #Basic packages for creating dataframes and loading dataset\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt #Package for visualization\n",
    "\n",
    "import re #importing package for Regular expression operations\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Package for splitting the data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #Package for conversion of categorical to Numerical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer #Tokenization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #Add zeros or crop based on the length\n",
    "from keras.models import Sequential #Sequential Neural Network\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #For layers in Neural Network\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd02f14-f62a-43da-a2a1-33a933a5cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0abe503-33be-4524-aed3-4c79f88a4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset as a Pandas DataFrame\n",
    "dataset = pd.read_csv('Sentiment.csv', header=0)\n",
    "\n",
    "# Select only the necessary columns 'text' and 'sentiment'\n",
    "mask = dataset.columns.isin(['text', 'sentiment'])\n",
    "#print(data.columns)\n",
    "data = dataset.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4e0313a-e1cd-4108-9869-03b69303a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/271qr1m16ss8v45r4_tfpn700000gn/T/ipykernel_13140/2214349272.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
      "/var/folders/2c/271qr1m16ss8v45r4_tfpn700000gn/T/ipykernel_13140/2214349272.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "942aaa1f-47c0-404c-8711-d0ac49fc6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/271qr1m16ss8v45r4_tfpn700000gn/T/ipykernel_13140/1671198718.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  row[0] = row[0].replace('rt', ' ') #Removing Retweets\n",
      "/var/folders/2c/271qr1m16ss8v45r4_tfpn700000gn/T/ipykernel_13140/1671198718.py:2: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[0] = row[0].replace('rt', ' ') #Removing Retweets\n"
     ]
    }
   ],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ') #Removing Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb010132-30f0-46e6-8c7c-fb3d5410ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ') #Maximum words is 2000 to tokenize sentence\n",
    "tokenizer.fit_on_texts(data['text'].values) \n",
    "X = tokenizer.texts_to_sequences(data['text'].values) #taking values to feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7f3e5b6-385a-4016-9568-b81d6a90bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X) #Padding the feature matrix\n",
    "\n",
    "embed_dim = 128 #Dimension of the Embedded layer\n",
    "lstm_out = 196 #Long short-term memory (LSTM) layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4836b734-7525-4783-bc13-53220067cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    model = Sequential() #Sequential Neural Network\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1])) #input dimension 2000 Neurons, output dimension 128 Neurons\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) #Drop out 20%, 196 output Neurons, recurrent dropout 20%\n",
    "    model.add(Dense(3,activation='softmax')) #3 output neurons[positive, Neutral, Negative], softmax as activation\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) #Compiling the model\n",
    "    return model\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc88c4a-a97e-47f3-9538-2e03bdac81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder() #Applying label Encoding on the label matrix\n",
    "integer_encoded = labelencoder.fit_transform(data['sentiment']) #fitting the model\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42) #67% training data, 33% test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bfd4248-19bb-4c70-925d-7d85b8dc51f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 - 23s - loss: 0.8266 - accuracy: 0.6447 - 23s/epoch - 79ms/step\n",
      "144/144 - 2s - loss: 0.7666 - accuracy: 0.6706 - 2s/epoch - 17ms/step\n",
      "0.7666078805923462\n",
      "0.6705985069274902\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #Batch size 32\n",
    "model = createmodel() #Function call to Sequential Neural Network\n",
    "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) #verbose the higher, the more messages\n",
    "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size) #evaluating the model\n",
    "print(score)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01e1d844-926a-4ef4-b692-45926fdf8c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names) #metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06219540-b2eb-44db-ab32-5c26d2650f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentimentAnalysis.h5') #Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90155b29-54e5-4ffe-a019-ab954f6507ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model #Importing the package for importing the saved model\n",
    "model= load_model('sentimentAnalysis.h5') #loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5500af8-fcbb-4db9-8600-c6a378bb7c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 0 2]\n",
      "0         Neutral\n",
      "1        Positive\n",
      "2         Neutral\n",
      "3        Positive\n",
      "4        Positive\n",
      "           ...   \n",
      "13866    Negative\n",
      "13867    Positive\n",
      "13868    Positive\n",
      "13869    Negative\n",
      "13870    Positive\n",
      "Name: sentiment, Length: 13871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(integer_encoded)\n",
    "print(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b74f0aee-01e3-4e2f-86e3-90333ab394c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - 21ms/epoch - 21ms/step\n",
      "[0.6091014  0.20005693 0.19084163]\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the text data\n",
    "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
    "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
    "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0) # Padding the sentence\n",
    "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
    "sentiment = np.argmax(sentiment_probs)\n",
    "print(sentiment_probs)\n",
    "if sentiment >= 0:\n",
    "    print(\"Positive\")\n",
    "elif sentiment < 0:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Cannot be determined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6236a965-3bab-4f67-aacb-6a0c6266861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/271qr1m16ss8v45r4_tfpn700000gn/T/ipykernel_13140/140920398.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=createmodel,verbose=2) #initiating model to test performance by applying multiple hyper parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 - 41s - loss: 0.8300 - accuracy: 0.6455 - 41s/epoch - 55ms/step\n",
      "186/186 - 2s - loss: 0.7596 - accuracy: 0.6740 - 2s/epoch - 10ms/step\n",
      "744/744 - 22s - loss: 0.8226 - accuracy: 0.6472 - 22s/epoch - 29ms/step\n",
      "186/186 - 1s - loss: 0.7721 - accuracy: 0.6708 - 738ms/epoch - 4ms/step\n",
      "744/744 - 15s - loss: 0.8229 - accuracy: 0.6450 - 15s/epoch - 20ms/step\n",
      "186/186 - 1s - loss: 0.7747 - accuracy: 0.6703 - 727ms/epoch - 4ms/step\n",
      "744/744 - 14s - loss: 0.8247 - accuracy: 0.6453 - 14s/epoch - 19ms/step\n",
      "186/186 - 1s - loss: 0.7523 - accuracy: 0.6760 - 709ms/epoch - 4ms/step\n",
      "744/744 - 15s - loss: 0.8194 - accuracy: 0.6410 - 15s/epoch - 20ms/step\n",
      "186/186 - 1s - loss: 0.7708 - accuracy: 0.6701 - 738ms/epoch - 4ms/step\n",
      "Epoch 1/2\n",
      "744/744 - 15s - loss: 0.8218 - accuracy: 0.6453 - 15s/epoch - 21ms/step\n",
      "Epoch 2/2\n",
      "744/744 - 14s - loss: 0.6757 - accuracy: 0.7168 - 14s/epoch - 18ms/step\n",
      "186/186 - 1s - loss: 0.7439 - accuracy: 0.6832 - 719ms/epoch - 4ms/step\n",
      "Epoch 1/2\n",
      "744/744 - 14s - loss: 0.8156 - accuracy: 0.6490 - 14s/epoch - 19ms/step\n",
      "Epoch 2/2\n",
      "744/744 - 14s - loss: 0.6783 - accuracy: 0.7089 - 14s/epoch - 18ms/step\n",
      "186/186 - 1s - loss: 0.7428 - accuracy: 0.6746 - 722ms/epoch - 4ms/step\n",
      "Epoch 1/2\n",
      "744/744 - 14s - loss: 0.8261 - accuracy: 0.6476 - 14s/epoch - 19ms/step\n",
      "Epoch 2/2\n",
      "744/744 - 14s - loss: 0.6742 - accuracy: 0.7174 - 14s/epoch - 18ms/step\n",
      "186/186 - 1s - loss: 0.7772 - accuracy: 0.6590 - 718ms/epoch - 4ms/step\n",
      "Epoch 1/2\n",
      "744/744 - 15s - loss: 0.8202 - accuracy: 0.6445 - 15s/epoch - 20ms/step\n",
      "Epoch 2/2\n",
      "744/744 - 13s - loss: 0.6709 - accuracy: 0.7135 - 13s/epoch - 18ms/step\n",
      "186/186 - 1s - loss: 0.7433 - accuracy: 0.6819 - 728ms/epoch - 4ms/step\n",
      "Epoch 1/2\n",
      "744/744 - 15s - loss: 0.8117 - accuracy: 0.6502 - 15s/epoch - 20ms/step\n",
      "Epoch 2/2\n",
      "744/744 - 14s - loss: 0.6658 - accuracy: 0.7204 - 14s/epoch - 18ms/step\n",
      "186/186 - 1s - loss: 0.7790 - accuracy: 0.6625 - 764ms/epoch - 4ms/step\n",
      "372/372 - 10s - loss: 0.8345 - accuracy: 0.6455 - 10s/epoch - 27ms/step\n",
      "93/93 - 1s - loss: 0.7874 - accuracy: 0.6584 - 617ms/epoch - 7ms/step\n",
      "372/372 - 10s - loss: 0.8321 - accuracy: 0.6490 - 10s/epoch - 27ms/step\n",
      "93/93 - 1s - loss: 0.7662 - accuracy: 0.6686 - 603ms/epoch - 6ms/step\n",
      "372/372 - 10s - loss: 0.8347 - accuracy: 0.6426 - 10s/epoch - 26ms/step\n",
      "93/93 - 1s - loss: 0.8279 - accuracy: 0.6557 - 579ms/epoch - 6ms/step\n",
      "372/372 - 10s - loss: 0.8294 - accuracy: 0.6421 - 10s/epoch - 26ms/step\n",
      "93/93 - 1s - loss: 0.7609 - accuracy: 0.6798 - 600ms/epoch - 6ms/step\n",
      "372/372 - 10s - loss: 0.8238 - accuracy: 0.6418 - 10s/epoch - 26ms/step\n",
      "93/93 - 1s - loss: 0.7763 - accuracy: 0.6674 - 603ms/epoch - 6ms/step\n",
      "Epoch 1/2\n",
      "372/372 - 10s - loss: 0.8351 - accuracy: 0.6429 - 10s/epoch - 26ms/step\n",
      "Epoch 2/2\n",
      "372/372 - 9s - loss: 0.6783 - accuracy: 0.7142 - 9s/epoch - 23ms/step\n",
      "93/93 - 1s - loss: 0.7394 - accuracy: 0.6724 - 594ms/epoch - 6ms/step\n",
      "Epoch 1/2\n",
      "372/372 - 10s - loss: 0.8333 - accuracy: 0.6414 - 10s/epoch - 26ms/step\n",
      "Epoch 2/2\n",
      "372/372 - 9s - loss: 0.6879 - accuracy: 0.7061 - 9s/epoch - 24ms/step\n",
      "93/93 - 1s - loss: 0.7383 - accuracy: 0.6832 - 607ms/epoch - 7ms/step\n",
      "Epoch 1/2\n",
      "372/372 - 10s - loss: 0.8277 - accuracy: 0.6402 - 10s/epoch - 27ms/step\n",
      "Epoch 2/2\n",
      "372/372 - 9s - loss: 0.6798 - accuracy: 0.7152 - 9s/epoch - 23ms/step\n",
      "93/93 - 1s - loss: 0.7549 - accuracy: 0.6810 - 605ms/epoch - 7ms/step\n",
      "Epoch 1/2\n",
      "372/372 - 10s - loss: 0.8341 - accuracy: 0.6416 - 10s/epoch - 26ms/step\n",
      "Epoch 2/2\n",
      "372/372 - 9s - loss: 0.6777 - accuracy: 0.7116 - 9s/epoch - 23ms/step\n",
      "93/93 - 1s - loss: 0.7399 - accuracy: 0.6851 - 627ms/epoch - 7ms/step\n",
      "Epoch 1/2\n",
      "372/372 - 10s - loss: 0.8233 - accuracy: 0.6438 - 10s/epoch - 26ms/step\n",
      "Epoch 2/2\n",
      "372/372 - 9s - loss: 0.6764 - accuracy: 0.7123 - 9s/epoch - 24ms/step\n",
      "93/93 - 1s - loss: 0.7957 - accuracy: 0.6712 - 608ms/epoch - 7ms/step\n",
      "186/186 - 7s - loss: 0.8412 - accuracy: 0.6377 - 7s/epoch - 36ms/step\n",
      "47/47 - 1s - loss: 0.7540 - accuracy: 0.6568 - 501ms/epoch - 11ms/step\n",
      "186/186 - 7s - loss: 0.8417 - accuracy: 0.6390 - 7s/epoch - 38ms/step\n",
      "47/47 - 1s - loss: 0.7800 - accuracy: 0.6654 - 550ms/epoch - 12ms/step\n",
      "186/186 - 7s - loss: 0.8482 - accuracy: 0.6334 - 7s/epoch - 36ms/step\n",
      "47/47 - 0s - loss: 0.7639 - accuracy: 0.6842 - 496ms/epoch - 11ms/step\n",
      "186/186 - 7s - loss: 0.8459 - accuracy: 0.6352 - 7s/epoch - 36ms/step\n",
      "47/47 - 0s - loss: 0.7668 - accuracy: 0.6668 - 493ms/epoch - 10ms/step\n",
      "186/186 - 7s - loss: 0.8466 - accuracy: 0.6285 - 7s/epoch - 36ms/step\n",
      "47/47 - 1s - loss: 0.8162 - accuracy: 0.6625 - 503ms/epoch - 11ms/step\n",
      "Epoch 1/2\n",
      "186/186 - 7s - loss: 0.8495 - accuracy: 0.6337 - 7s/epoch - 36ms/step\n",
      "Epoch 2/2\n",
      "186/186 - 6s - loss: 0.6943 - accuracy: 0.7061 - 6s/epoch - 31ms/step\n",
      "47/47 - 1s - loss: 0.7436 - accuracy: 0.6794 - 502ms/epoch - 11ms/step\n",
      "Epoch 1/2\n",
      "186/186 - 7s - loss: 0.8388 - accuracy: 0.6426 - 7s/epoch - 36ms/step\n",
      "Epoch 2/2\n",
      "186/186 - 6s - loss: 0.6940 - accuracy: 0.7049 - 6s/epoch - 31ms/step\n",
      "47/47 - 1s - loss: 0.7394 - accuracy: 0.6756 - 514ms/epoch - 11ms/step\n",
      "Epoch 1/2\n",
      "186/186 - 7s - loss: 0.8411 - accuracy: 0.6352 - 7s/epoch - 36ms/step\n",
      "Epoch 2/2\n",
      "186/186 - 6s - loss: 0.6839 - accuracy: 0.7057 - 6s/epoch - 31ms/step\n",
      "47/47 - 1s - loss: 0.7310 - accuracy: 0.6934 - 576ms/epoch - 12ms/step\n",
      "Epoch 1/2\n",
      "186/186 - 7s - loss: 0.8479 - accuracy: 0.6343 - 7s/epoch - 39ms/step\n",
      "Epoch 2/2\n",
      "186/186 - 6s - loss: 0.6831 - accuracy: 0.7119 - 6s/epoch - 33ms/step\n",
      "47/47 - 1s - loss: 0.7345 - accuracy: 0.6798 - 522ms/epoch - 11ms/step\n",
      "Epoch 1/2\n",
      "186/186 - 7s - loss: 0.8381 - accuracy: 0.6351 - 7s/epoch - 38ms/step\n",
      "Epoch 2/2\n",
      "186/186 - 6s - loss: 0.6785 - accuracy: 0.7107 - 6s/epoch - 32ms/step\n",
      "47/47 - 1s - loss: 0.7793 - accuracy: 0.6685 - 521ms/epoch - 11ms/step\n",
      "Epoch 1/2\n",
      "233/233 - 9s - loss: 0.8312 - accuracy: 0.6418 - 9s/epoch - 37ms/step\n",
      "Epoch 2/2\n",
      "233/233 - 7s - loss: 0.6774 - accuracy: 0.7119 - 7s/epoch - 31ms/step\n",
      "Best: 0.679327 using {'batch_size': 40, 'epochs': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier #importing Keras classifier\n",
    "from sklearn.model_selection import GridSearchCV #importing Grid search CV\n",
    "\n",
    "model = KerasClassifier(build_fn=createmodel,verbose=2) #initiating model to test performance by applying multiple hyper parameters\n",
    "batch_size= [10, 20, 40] #hyper parameter batch_size\n",
    "epochs = [1, 2] #hyper parameter no. of epochs\n",
    "param_grid= {'batch_size':batch_size, 'epochs':epochs} #creating dictionary for batch size, no. of epochs\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid) #Applying dictionary with hyper parameters\n",
    "grid_result= grid.fit(X_train,Y_train) #Fitting the model\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) #best score, best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0daa990-84ba-4426-aada-eea2f43a4678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
